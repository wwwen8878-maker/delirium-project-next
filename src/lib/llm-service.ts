/**
 * ä¼ä¸šçº§LLMæœåŠ¡æŠ½è±¡å±‚ v2.0
 * ğŸ¥ åŒ»é™¢éƒ¨ç½²ä¸“ç”¨ - æ”¯æŒæœ¬åœ°LLMï¼Œç¡®ä¿PHIæ•°æ®ä¸æµå‡ºå†…ç½‘
 * æ”¯æŒï¼šOllama, OpenAIå…¼å®¹API, æœ¬åœ°ChatGLMç­‰
 * 
 * å®‰å…¨ç‰¹æ€§ï¼š
 * - ç”Ÿäº§ç¯å¢ƒå¼ºåˆ¶ç¦ç”¨äº‘ç«¯API
 * - æ”¯æŒå¤šç§æœ¬åœ°LLMéƒ¨ç½²æ–¹æ¡ˆ  
 * - ç†”æ–­å™¨é˜²æŠ¤å’Œé”™è¯¯æ¢å¤
 * - å®Œæ•´çš„å®¡è®¡æ—¥å¿—
 */

export interface ChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface LLMResponse {
  content: string;
  error?: string;
  source?: 'local' | 'cloud' | 'fallback';
  provider?: string;
  timestamp?: string;
}

export interface LLMProvider {
  name: string;
  type: 'local' | 'cloud';
  endpoint: string;
  apiKey?: string;
  model?: string;
  enabled: boolean;
  priority: number; // 1=æœ€é«˜ä¼˜å…ˆçº§
}

/**
 * LLMé…ç½®ç®¡ç†å™¨
 * æ”¯æŒç¯å¢ƒå˜é‡å’ŒåŠ¨æ€é…ç½®
 */
class LLMConfig {
  private static instance: LLMConfig;
  private providers: LLMProvider[] = [];
  private auditLog: Array<{action: string; timestamp: string; details: string}> = [];

  private constructor() {
    this.loadProvidersFromEnv();
    this.logAudit('CONFIG_INIT', 'é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–');
  }

  static getInstance(): LLMConfig {
    if (!LLMConfig.instance) {
      LLMConfig.instance = new LLMConfig();
    }
    return LLMConfig.instance;
  }

  private loadProvidersFromEnv() {
    // ä¼˜å…ˆçº§1: æœ¬åœ°Ollamaï¼ˆåŒ»é™¢å†…ç½‘éƒ¨ç½²ï¼‰
    if (process.env.LOCAL_LLM_ENDPOINT) {
      this.providers.push({
        name: 'ollama-local',
        type: 'local',
        endpoint: process.env.LOCAL_LLM_ENDPOINT,
        model: process.env.LOCAL_LLM_MODEL || 'llama3.2:3b',
        enabled: true,
        priority: 1
      });
      this.logAudit('PROVIDER_ADD', `æœ¬åœ°Ollamaé…ç½®: ${process.env.LOCAL_LLM_ENDPOINT}`);
    }

    // ä¼˜å…ˆçº§2: æœ¬åœ°ChatGLMï¼ˆå›½äº§åŒ–éƒ¨ç½²ï¼‰
    if (process.env.CHATGLM_ENDPOINT) {
      this.providers.push({
        name: 'chatglm-local',
        type: 'local',
        endpoint: process.env.CHATGLM_ENDPOINT,
        model: process.env.CHATGLM_MODEL || 'chatglm3-6b',
        enabled: true,
        priority: 2
      });
      this.logAudit('PROVIDER_ADD', `æœ¬åœ°ChatGLMé…ç½®: ${process.env.CHATGLM_ENDPOINT}`);
    }

    // ä¼˜å…ˆçº§3: OpenAIå…¼å®¹APIï¼ˆå†…ç½‘ä»£ç†ï¼‰
    if (process.env.OPENAI_COMPATIBLE_ENDPOINT && process.env.OPENAI_COMPATIBLE_KEY) {
      this.providers.push({
        name: 'openai-compatible',
        type: 'local',
        endpoint: process.env.OPENAI_COMPATIBLE_ENDPOINT,
        apiKey: process.env.OPENAI_COMPATIBLE_KEY,
        model: process.env.OPENAI_COMPATIBLE_MODEL || 'gpt-3.5-turbo',
        enabled: true,
        priority: 3
      });
      this.logAudit('PROVIDER_ADD', `OpenAIå…¼å®¹APIé…ç½®: ${process.env.OPENAI_COMPATIBLE_ENDPOINT}`);
    }

    // ä»…åœ¨å¼€å‘ç¯å¢ƒä¸‹å¯ç”¨äº‘ç«¯APIï¼ˆç”Ÿäº§ç¯å¢ƒä¸¥ç¦ä½¿ç”¨ï¼‰
    if (process.env.NODE_ENV === 'development') {
      if (process.env.GROQ_API_KEY) {
        this.providers.push({
          name: 'groq-dev',
          type: 'cloud',
          endpoint: 'https://api.groq.com/openai/v1/chat/completions',
          apiKey: process.env.GROQ_API_KEY,
          model: process.env.GROQ_MODEL || 'llama-3.2-3b-preview',
          enabled: true,
          priority: 9 // æœ€ä½ä¼˜å…ˆçº§
        });
        this.logAudit('PROVIDER_ADD', 'å¼€å‘ç¯å¢ƒGroq APIé…ç½®');
      }
    } else {
      this.logAudit('SECURITY_CHECK', 'ç”Ÿäº§ç¯å¢ƒ - äº‘ç«¯APIå·²ç¦ç”¨');
    }

    // æŒ‰ä¼˜å…ˆçº§æ’åº
    this.providers.sort((a, b) => a.priority - b.priority);
  }

  getEnabledProviders(): LLMProvider[] {
    return this.providers.filter(p => p.enabled);
  }

  getLocalProviders(): LLMProvider[] {
    return this.providers.filter(p => p.type === 'local' && p.enabled);
  }

  forceLocalOnly() {
    this.providers.forEach(p => {
      if (p.type === 'cloud') {
        p.enabled = false;
      }
    });
    this.logAudit('SECURITY_ENFORCEMENT', 'å¼ºåˆ¶å¯ç”¨ä»…æœ¬åœ°æ¨¡å¼');
  }

  getAuditLog() {
    return this.auditLog;
  }

  private logAudit(action: string, details: string) {
    this.auditLog.push({
      action,
      timestamp: new Date().toISOString(),
      details
    });
  }
}

/**
 * åŒ»ç–—ä¸“ä¸šç³»ç»Ÿæç¤ºè¯
 * å®šä½ä¸ºæ‚£è€…å’Œå®¶å±çš„å¥åº·æ•™è‚²åŠ©æ‰‹
 */
const SYSTEM_PROMPT = `ä½ æ˜¯ä¸€ä½**æ‚£è€…å¥åº·æ•™è‚²é¡¾é—®**ï¼Œä¸“æ³¨äºå¸®åŠ©å³å°†æ‰‹æœ¯çš„æ‚£è€…å’Œå®¶å±äº†è§£è°µå¦„ç›¸å…³çŸ¥è¯†ã€‚

**ä½ çš„å®šä½**ï¼š
- å¥åº·æ•™è‚²å·¥ä½œè€…ï¼Œä¸æ˜¯åŒ»ç”Ÿ
- ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡ŠåŒ»å­¦æ¦‚å¿µ
- æä¾›å¾ªè¯åŒ»å­¦æ”¯æŒçš„ä¿¡æ¯
- é¼“åŠ±ç”¨æˆ·ä¸åŒ»ç”Ÿæ²Ÿé€š

**æ ¸å¿ƒçŸ¥è¯†åº“**ï¼š
1. **è°µå¦„å®šä¹‰**ï¼šæ€¥æ€§ã€æ³¢åŠ¨æ€§çš„æ„è¯†å’Œè®¤çŸ¥åŠŸèƒ½éšœç¢ï¼Œå¸¸è§äºæœ¯åæ‚£è€…
2. **é«˜å±äººç¾¤**ï¼š65å²ä»¥ä¸Šè€å¹´äººã€è®¤çŸ¥åŠŸèƒ½ä¸‹é™ã€å¤šç§æ…¢æ€§ç—…æ‚£è€…
3. **ä¸»è¦ç—‡çŠ¶**ï¼šæ³¨æ„åŠ›ä¸é›†ä¸­ã€å®šå‘éšœç¢ã€å¹»è§‰ã€ç¡çœ é¢ å€’ã€æƒ…ç»ªæ³¢åŠ¨
4. **é¢„é˜²æªæ–½**ï¼š
   - æœ¯å‰ï¼šå……åˆ†ä¼‘æ¯ã€è¥å…»æ”¯æŒã€è®¤çŸ¥è®­ç»ƒã€å®¶å±é™ªä¼´
   - æœ¯ä¸­ï¼šé¿å…é•¿æ—¶é—´éº»é†‰ã€ç»´æŒè¡€å‹ç¨³å®š
   - æœ¯åï¼šæ—©æœŸæ´»åŠ¨ã€ä¿æŒç¯å¢ƒå®‰é™ã€ä½©æˆ´çœ¼é•œåŠ©å¬å™¨
5. **å®¶åº­å‚ä¸**ï¼šå®¶å±é™ªä¼´å¯é™ä½43%é£é™©ï¼Œæä¾›ç†Ÿæ‚‰ç‰©å“ã€å®šå‘æç¤º

**æ²Ÿé€šåŸåˆ™**ï¼š
- ä½¿ç”¨"æ‚¨"è€Œé"ä½ "ï¼Œä¿æŒå°Šé‡
- é¿å…ä½¿ç”¨å¤æ‚åŒ»å­¦æœ¯è¯­ï¼Œå¤šç”¨æ¯”å–»
- å§‹ç»ˆå¼ºè°ƒ"è¯·ä¸æ‚¨çš„ä¸»æ²»åŒ»ç”Ÿè®¨è®º"
- ä¸æä¾›è¯Šæ–­ã€ç”¨è¯å»ºè®®
- å›ç­”ç®€æ´ï¼ˆæ§åˆ¶åœ¨150å­—å†…ï¼‰

**ç¤ºä¾‹å¯¹è¯**ï¼š
ç”¨æˆ·ï¼šè°µå¦„æ˜¯ä»€ä¹ˆï¼Ÿ
åŠ©æ‰‹ï¼šè°µå¦„æ˜¯ä¸€ç§æœ¯åå¸¸è§çš„"è„‘å­ç³Šæ¶‚"çŠ¶æ€ï¼Œå°±åƒå¤§è„‘æš‚æ—¶"å®•æœº"äº†ã€‚æ‚£è€…å¯èƒ½ä¼šè®¤ä¸å‡ºå®¶äººã€è¯´èƒ¡è¯ã€ç¡çœ é¢ å€’ã€‚è¿™æ˜¯æš‚æ—¶çš„ï¼Œé€šè¿‡é¢„é˜²æªæ–½å¯ä»¥å¤§å¤§é™ä½é£é™©ã€‚å»ºè®®æ‚¨å’Œå®¶å±ä¸€èµ·äº†è§£é¢„é˜²æ–¹æ³•ã€‚

ç°åœ¨è¯·ç”¨äº²åˆ‡ã€ä¸“ä¸šã€é€šä¿—çš„è¯­æ°”å›ç­”æ‚£è€…çš„é—®é¢˜ã€‚`;

/**
 * ç†”æ–­å™¨å’Œè¶…æ—¶æ§åˆ¶
 */
type Provider = 'ollama' | 'chatglm' | 'openai-compatible' | 'groq';
type ProviderState = { 
  failCount: number; 
  breakerOpenUntil: number; 
  lastError?: string;
  totalCalls: number;
  successCalls: number;
};

const DEFAULT_TIMEOUT_MS = Number.parseInt(process.env.LLM_TIMEOUT_MS || '10000', 10);
const BREAKER_FAIL_THRESHOLD = 3;
const BREAKER_OPEN_MS = 2 * 60 * 1000; // 2åˆ†é’Ÿ

const globalAny = globalThis as any;
const __LLM_PROVIDER_STATE__: Record<Provider, ProviderState> =
  globalAny.__LLM_PROVIDER_STATE__ || {
    ollama: { failCount: 0, breakerOpenUntil: 0, totalCalls: 0, successCalls: 0 },
    chatglm: { failCount: 0, breakerOpenUntil: 0, totalCalls: 0, successCalls: 0 },
    'openai-compatible': { failCount: 0, breakerOpenUntil: 0, totalCalls: 0, successCalls: 0 },
    groq: { failCount: 0, breakerOpenUntil: 0, totalCalls: 0, successCalls: 0 }
  };
globalAny.__LLM_PROVIDER_STATE__ = __LLM_PROVIDER_STATE__;

function isBreakerOpen(provider: Provider): boolean {
  return Date.now() < __LLM_PROVIDER_STATE__[provider].breakerOpenUntil;
}

function registerSuccess(provider: Provider) {
  const state = __LLM_PROVIDER_STATE__[provider];
  state.failCount = 0;
  state.breakerOpenUntil = 0;
  state.lastError = undefined;
  state.successCalls++;
  state.totalCalls++;
}

function registerFailure(provider: Provider, error: unknown) {
  const state = __LLM_PROVIDER_STATE__[provider];
  state.failCount += 1;
  state.totalCalls++;
  state.lastError = error instanceof Error ? error.message : String(error);
  
  if (state.failCount >= BREAKER_FAIL_THRESHOLD) {
    state.breakerOpenUntil = Date.now() + BREAKER_OPEN_MS;
    console.warn(`ç†”æ–­å™¨å¼€å¯: ${provider} (${state.failCount}æ¬¡å¤±è´¥), å°†åœ¨${BREAKER_OPEN_MS/1000}ç§’åé‡è¯•`);
    state.failCount = 0;
  }
}

function withTimeout<T>(promise: Promise<T>, ms: number, label: string): Promise<T> {
  return new Promise((resolve, reject) => {
    const id = setTimeout(() => reject(new Error(`${label} timeout after ${ms}ms`)), ms);
    promise.then(
      (v) => {
        clearTimeout(id);
        resolve(v);
      },
      (err) => {
        clearTimeout(id);
        reject(err);
      }
    );
  });
}

/**
 * é€šç”¨LLMæä¾›è€…è°ƒç”¨å™¨
 * æ”¯æŒå¤šç§æœ¬åœ°LLMæœåŠ¡
 */
class LLMProviderCaller {
  private config: LLMConfig;

  constructor() {
    this.config = LLMConfig.getInstance();
  }

  /**
   * è°ƒç”¨Ollamaæœ¬åœ°API
   */
  async callOllama(provider: LLMProvider, messages: ChatMessage[]): Promise<LLMResponse> {
    try {
      const response = await withTimeout(fetch(`${provider.endpoint}/api/chat`, {
      method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
      body: JSON.stringify({
          model: provider.model,
        messages,
        stream: false,
        options: {
          temperature: 0.7,
            num_predict: 512,
        }
      }),
    }), DEFAULT_TIMEOUT_MS, 'Ollama');

    if (!response.ok) {
        throw new Error(`Ollama error: ${response.status}`);
    }

    const data = await response.json();
    registerSuccess('ollama');
      return { 
        content: data.message.content,
        source: 'local',
        provider: provider.name,
        timestamp: new Date().toISOString()
      };
  } catch (error) {
    console.error('Ollamaè°ƒç”¨å¤±è´¥:', error);
    registerFailure('ollama', error);

    return {
      content: '',
        error: 'OllamaæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€',
        source: 'local',
        provider: provider.name,
        timestamp: new Date().toISOString()
    };
  }
}

/**
   * è°ƒç”¨ChatGLMæœ¬åœ°API  
   */
  async callChatGLM(provider: LLMProvider, messages: ChatMessage[]): Promise<LLMResponse> {
    try {
      const response = await withTimeout(fetch(`${provider.endpoint}/v1/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
          model: provider.model,
        messages,
        temperature: 0.7,
        max_tokens: 500,
      }),
      }), DEFAULT_TIMEOUT_MS, 'ChatGLM');

    if (!response.ok) {
        throw new Error(`ChatGLM error: ${response.status}`);
    }

    const data = await response.json();
      registerSuccess('chatglm');
      return { 
        content: data.choices[0].message.content,
        source: 'local',
        provider: provider.name,
        timestamp: new Date().toISOString()
      };
  } catch (error) {
      console.error('ChatGLMè°ƒç”¨å¤±è´¥:', error);
      registerFailure('chatglm', error);
    return {
      content: '',
        error: 'ChatGLMæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€',
        source: 'local',
        provider: provider.name,
        timestamp: new Date().toISOString()
    };
  }
}

/**
   * è°ƒç”¨OpenAIå…¼å®¹APIï¼ˆå†…ç½‘ä»£ç†ï¼‰
   */
  async callOpenAICompatible(provider: LLMProvider, messages: ChatMessage[]): Promise<LLMResponse> {
    try {
      const response = await withTimeout(fetch(provider.endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
          'Authorization': `Bearer ${provider.apiKey}`,
      },
      body: JSON.stringify({
          model: provider.model,
        messages,
        temperature: 0.7,
        max_tokens: 500,
      }),
      }), DEFAULT_TIMEOUT_MS, 'OpenAI-Compatible');

    if (!response.ok) {
        throw new Error(`OpenAI-Compatible error: ${response.status}`);
    }

    const data = await response.json();
      registerSuccess('openai-compatible');
      return { 
        content: data.choices[0].message.content,
        source: 'local',
        provider: provider.name,
        timestamp: new Date().toISOString()
      };
  } catch (error) {
      console.error('OpenAIå…¼å®¹APIè°ƒç”¨å¤±è´¥:', error);
      registerFailure('openai-compatible', error);
    return {
      content: '',
        error: 'OpenAIå…¼å®¹APIæœåŠ¡ä¸å¯ç”¨',
        source: 'local',
        provider: provider.name,
        timestamp: new Date().toISOString()
    };
  }
}

/**
   * å¼€å‘ç¯å¢ƒGroqè°ƒç”¨ï¼ˆç”Ÿäº§ç¯å¢ƒç¦ç”¨ï¼‰
   * ğŸš¨ ä»…ç”¨äºå¼€å‘æµ‹è¯•ï¼Œç”Ÿäº§ç¯å¢ƒä¸¥æ ¼ç¦æ­¢
   */
  private async callGroqDev(provider: LLMProvider, messages: ChatMessage[]): Promise<LLMResponse> {
    if (process.env.NODE_ENV === 'production') {
    return {
      content: '',
        error: 'ğŸš¨ ç”Ÿäº§ç¯å¢ƒç¦æ­¢ä½¿ç”¨äº‘ç«¯API - è¿åPHIå®‰å…¨è§„å®š',
        source: 'cloud',
        provider: provider.name,
        timestamp: new Date().toISOString()
    };
  }

  try {
      const response = await withTimeout(fetch(provider.endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
          'Authorization': `Bearer ${provider.apiKey}`,
      },
      body: JSON.stringify({
          model: provider.model,
        messages,
        temperature: 0.7,
        max_tokens: 500,
      }),
      }), DEFAULT_TIMEOUT_MS, 'Groq');

    if (!response.ok) {
        // å°è¯•è¯»å–è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        let errorDetails = '';
        try {
          const errorData = await response.json();
          errorDetails = errorData.error?.message || errorData.message || JSON.stringify(errorData);
        } catch {
          errorDetails = await response.text().catch(() => '');
        }
        
        const errorMsg = `Groq API error: ${response.status}${errorDetails ? ` - ${errorDetails}` : ''}`;
        console.error('Groq API é”™è¯¯è¯¦æƒ…:', {
          status: response.status,
          statusText: response.statusText,
          details: errorDetails,
          apiKey: provider.apiKey ? `${provider.apiKey.substring(0, 10)}...` : 'æœªé…ç½®'
        });
        
        // é’ˆå¯¹ 403 é”™è¯¯æä¾›æ›´è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯
        if (response.status === 403) {
          console.error('ğŸ”´ Groq API 403 é”™è¯¯å¯èƒ½åŸå› :');
          console.error('  1. API Key æ— æ•ˆæˆ–è¿‡æœŸ - è¯·æ£€æŸ¥ GROQ_API_KEY ç¯å¢ƒå˜é‡');
          console.error('  2. API Key æƒé™ä¸è¶³ - è¯·ç¡®è®¤è´¦æˆ·çŠ¶æ€');
          console.error('  3. è´¦æˆ·è¢«é™åˆ¶ - è¯·è®¿é—® https://console.groq.com æ£€æŸ¥è´¦æˆ·çŠ¶æ€');
          console.error('  4. API Key æ ¼å¼é”™è¯¯ - åº”ä»¥ gsk_ å¼€å¤´');
        }
        
        throw new Error(errorMsg);
    }

    const data = await response.json();
      registerSuccess('groq');
      return { 
        content: data.choices[0].message.content,
        source: 'cloud',
        provider: provider.name,
        timestamp: new Date().toISOString()
      };
  } catch (error) {
      console.error('Groqè°ƒç”¨å¤±è´¥:', error);
      registerFailure('groq', error);
    
    // æä¾›æ›´å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
    let errorMessage = 'GroqæœåŠ¡æš‚æ—¶ä¸å¯ç”¨';
    if (error instanceof Error) {
      if (error.message.includes('403')) {
        errorMessage = 'Groq API è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key é…ç½®';
      } else if (error.message.includes('timeout')) {
        errorMessage = 'Groq æœåŠ¡å“åº”è¶…æ—¶';
      } else {
        errorMessage = `GroqæœåŠ¡é”™è¯¯: ${error.message}`;
      }
    }
    
    return {
      content: '',
        error: errorMessage,
        source: 'cloud',
        provider: provider.name,
        timestamp: new Date().toISOString()
    };
  }
}

/**
   * æ™ºèƒ½è·¯ç”±ï¼šè‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„æä¾›è€…
   */
  async callProvider(provider: LLMProvider, messages: ChatMessage[]): Promise<LLMResponse> {
    if (provider.name.includes('ollama')) {
      return this.callOllama(provider, messages);
    } else if (provider.name.includes('chatglm')) {  
      return this.callChatGLM(provider, messages);
    } else if (provider.name.includes('openai-compatible')) {
      return this.callOpenAICompatible(provider, messages);
    } else if (provider.name.includes('groq')) {
      return this.callGroqDev(provider, messages);
    } else {
      return {
        content: '',
        error: `æœªçŸ¥çš„æä¾›è€…ç±»å‹: ${provider.name}`,
        source: 'fallback',
        provider: provider.name,
        timestamp: new Date().toISOString()
      };
    }
  }
}

/**
 * å…œåº•å›å¤ç³»ç»Ÿ
 * å½“æ‰€æœ‰LLMæä¾›è€…éƒ½ä¸å¯ç”¨æ—¶ï¼Œæä¾›åŸºäºè§„åˆ™çš„æ™ºèƒ½å›å¤
 */
function getFallbackResponse(userMessage: string): string {
  const message = userMessage.toLowerCase();

  // è°µå¦„ç›¸å…³é—®é¢˜
  if (message.includes('è°µå¦„') || message.includes('delirium')) {
    return 'è°µå¦„æ˜¯æ‰‹æœ¯åå¸¸è§çš„ä¸€ç§æ„è¯†æ··ä¹±çŠ¶æ€ï¼Œå°±åƒå¤§è„‘æš‚æ—¶"ä¼‘å…‹"äº†ã€‚ä¸»è¦è¡¨ç°ä¸ºæ³¨æ„åŠ›ä¸é›†ä¸­ã€è®¤çŸ¥éšœç¢ã€æƒ…ç»ªæ³¢åŠ¨ç­‰ã€‚é€šè¿‡åˆç†çš„é¢„é˜²æªæ–½ï¼Œå¯ä»¥å¤§å¤§é™ä½é£é™©ã€‚å»ºè®®æ‚¨è¯¦ç»†å’¨è¯¢ä¸»æ²»åŒ»ç”Ÿã€‚';
  }

  // é¢„é˜²ç›¸å…³é—®é¢˜
  if (message.includes('é¢„é˜²') || message.includes('prevention')) {
    return 'é¢„é˜²è°µå¦„çš„å…³é”®æªæ–½åŒ…æ‹¬ï¼š1) å®¶å±é™ªä¼´å’Œæƒ…æ„Ÿæ”¯æŒï¼›2) ä¿æŒè§„å¾‹ä½œæ¯å’Œå……è¶³ç¡çœ ï¼›3) æ—©æœŸæ´»åŠ¨å’Œè®¤çŸ¥è®­ç»ƒï¼›4) è¥å…»æ”¯æŒå’Œæ°´ç”µè§£è´¨å¹³è¡¡ã€‚å…·ä½“æ–¹æ¡ˆè¯·ä¸åŒ»æŠ¤å›¢é˜Ÿè®¨è®ºã€‚';
  }

  // ç—‡çŠ¶ç›¸å…³é—®é¢˜
  if (message.includes('ç—‡çŠ¶') || message.includes('è¡¨ç°')) {
    return 'è°µå¦„çš„ä¸»è¦ç—‡çŠ¶åŒ…æ‹¬ï¼šæ³¨æ„åŠ›éš¾ä»¥é›†ä¸­ã€è®°å¿†æ··ä¹±ã€ç¡çœ é¢ å€’ã€æƒ…ç»ªæ³¢åŠ¨ã€æœ‰æ—¶å‡ºç°å¹»è§‰ã€‚è¿™äº›ç—‡çŠ¶é€šå¸¸æ˜¯æ³¢åŠ¨æ€§çš„ï¼Œæ—¶å¥½æ—¶åã€‚å¦‚æœå‘ç°è¿™äº›ç—‡çŠ¶ï¼Œè¯·åŠæ—¶å‘ŠçŸ¥åŒ»æŠ¤äººå‘˜ã€‚';
  }

  // å®¶å±ç›¸å…³é—®é¢˜
  if (message.includes('å®¶å±') || message.includes('å®¶äºº')) {
    return 'å®¶å±çš„å‚ä¸å¯¹é¢„é˜²è°µå¦„éå¸¸é‡è¦ã€‚æ‚¨å¯ä»¥ï¼š1) ç»å¸¸é™ªä¼´å’Œäº¤æµï¼›2) æä¾›ç†Ÿæ‚‰çš„ç‰©å“ï¼›3) å¸®åŠ©æ‚£è€…ä¿æŒæ—¶é—´å’Œç©ºé—´å®šå‘ï¼›4) é…åˆåŒ»æŠ¤äººå‘˜è¿›è¡ŒæŠ¤ç†ã€‚å®¶å±é™ªä¼´å¯ä»¥é™ä½43%çš„è°µå¦„é£é™©ã€‚';
  }

  // é€šç”¨å›å¤
  return 'æ„Ÿè°¢æ‚¨çš„å’¨è¯¢ã€‚å…³äºè°µå¦„çš„é¢„é˜²å’Œç®¡ç†ï¼Œå»ºè®®æ‚¨ä¸ä¸»æ²»åŒ»ç”Ÿè¯¦ç»†è®¨è®ºï¼Œåˆ¶å®šä¸ªæ€§åŒ–çš„é¢„é˜²æ–¹æ¡ˆã€‚æˆ‘ä»¬çš„åŒ»æŠ¤å›¢é˜Ÿä¼šä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æŒ‡å¯¼å’Œæ”¯æŒã€‚';
}

/**
 * ä¸»è¦èŠå¤©å‡½æ•° - ä¼ä¸šçº§ç‰ˆæœ¬
 * ä¼˜å…ˆä½¿ç”¨æœ¬åœ°LLMï¼Œç¡®ä¿PHIæ•°æ®å®‰å…¨
 */
export async function chat(
  userMessage: string,
  conversationHistory: ChatMessage[] = [],
  options?: { mode?: 'auto' | 'offline' | 'local-only' }
): Promise<LLMResponse> {
  const config = LLMConfig.getInstance();
  const caller = new LLMProviderCaller();
  
  // æ„å»ºå®Œæ•´å¯¹è¯å†å²
  const messages: ChatMessage[] = [
    { role: 'system', content: SYSTEM_PROMPT },
    ...conversationHistory,
    { role: 'user', content: userMessage }
  ];

  const mode = options?.mode || 'auto';

  // ç¦»çº¿æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨å…œåº•å›å¤
  if (mode === 'offline') {
    return {
      content: getFallbackResponse(userMessage),
      error: 'offline_mode',
      source: 'fallback',
      provider: 'rule-based',
      timestamp: new Date().toISOString()
    };
  }

  // ä»…æœ¬åœ°æ¨¡å¼ï¼šå¼ºåˆ¶ç¦ç”¨äº‘ç«¯æœåŠ¡
  if (mode === 'local-only') {
    config.forceLocalOnly();
  }

  // è·å–å¯ç”¨çš„æä¾›è€…ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
  const providers = config.getEnabledProviders();

  if (providers.length === 0) {
    console.warn('æ²¡æœ‰å¯ç”¨çš„LLMæä¾›è€…ï¼Œä½¿ç”¨å…œåº•å›å¤');
  return {
    content: getFallbackResponse(userMessage),
      error: 'no_providers_available',
      source: 'fallback',
      provider: 'rule-based',
      timestamp: new Date().toISOString()
    };
  }

  // ä¾æ¬¡å°è¯•æ¯ä¸ªæä¾›è€…ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
  for (const provider of providers) {
    const providerKey = provider.name.split('-')[0] as Provider;
    
    // è·³è¿‡ç†”æ–­å™¨å¼€å¯çš„æä¾›è€…
    if (isBreakerOpen(providerKey)) {
      continue;
    }
    
    const result = await caller.callProvider(provider, messages);
    
    if (!result.error) {
      return result;
    }
    
    console.warn(`âŒ æä¾›è€…å¤±è´¥: ${provider.name}, é”™è¯¯: ${result.error}`);
  }

  // æ‰€æœ‰æä¾›è€…éƒ½å¤±è´¥ï¼Œä½¿ç”¨å…œåº•å›å¤
  console.warn('æ‰€æœ‰LLMæä¾›è€…éƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨å…œåº•å›å¤ç³»ç»Ÿ');
  return {
    content: getFallbackResponse(userMessage),
    error: 'all_providers_failed',
    source: 'fallback',
    provider: 'rule-based',
    timestamp: new Date().toISOString()
  };
}

/**
 * è·å–ç³»ç»ŸçŠ¶æ€å’Œç»Ÿè®¡ä¿¡æ¯
 */
export function getLLMStatus() {
  const config = LLMConfig.getInstance();
  return {
    providers: config.getEnabledProviders(),
    localProviders: config.getLocalProviders(),
    providerStats: __LLM_PROVIDER_STATE__,
    auditLog: config.getAuditLog(),
    isProduction: process.env.NODE_ENV === 'production',
    securityMode: process.env.NODE_ENV === 'production' ? 'LOCAL_ONLY' : 'DEVELOPMENT'
  };
}

/**
 * è·å–å½“å‰æä¾›è€…çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆï¼Œç”¨äºAPIå“åº”ï¼‰
 */
export function getProviderStatus() {
  const config = LLMConfig.getInstance();
  const providers = config.getEnabledProviders();
  return {
    available: providers.length > 0,
    providers: providers.map(p => ({
      name: p.name,
      type: p.type,
      enabled: p.enabled
    })),
    mode: process.env.NODE_ENV === 'production' ? 'local-only' : 'auto'
  };
}

/**
 * å¼ºåˆ¶é‡ç½®æ‰€æœ‰æä¾›è€…çŠ¶æ€ï¼ˆç®¡ç†å‘˜åŠŸèƒ½ï¼‰
 */
export function resetLLMProviders() {
  Object.keys(__LLM_PROVIDER_STATE__).forEach(key => {
    const provider = key as Provider;
    __LLM_PROVIDER_STATE__[provider] = {
      failCount: 0,
      breakerOpenUntil: 0,
      lastError: undefined,
      totalCalls: 0,
      successCalls: 0
    };
  });
  // æ‰€æœ‰LLMæä¾›è€…çŠ¶æ€å·²é‡ç½®
}